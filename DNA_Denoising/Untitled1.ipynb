{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import Parsing as ps\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import tetra_dude as td\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import *\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from numpy import *\n",
    "%matplotlib inline \n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam, Adadelta\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing starts...\n",
      "Pre-processing is 0.0% done..\n",
      "Pre-processing is 16.5% done..\n",
      "Pre-processing is 33.0% done..\n",
      "Pre-processing is 49.5% done..\n",
      "Pre-processing is 66.0% done..\n",
      "Pre-processing is 82.5% done..\n",
      "Pre-processing is 99.0% done..\n",
      "Reshaping...\n",
      "Pre-processing is completed!!\n",
      "Making PI starts...\n",
      "Making PI is 0.0% done..\n",
      "Making PI is 16.8% done..\n",
      "Making PI is 33.6% done..\n",
      "Making PI is 50.4% done..\n",
      "Making PI is 67.2% done..\n",
      "Making PI is 84.0% done..\n",
      "Making PI is completed!!\n"
     ]
    }
   ],
   "source": [
    "clean_dict = ps.clean('./',92)\n",
    "new = ps.noisy_head_info('./',1211177, clean_dict)\n",
    "PI = ps.make_PI(new)\n",
    "\n",
    "with open(\"Illumina_LinErr_100_fold1.fasta\", \"w\") as f:\n",
    "    for i in range(len(new)):\n",
    "        data = \"%s\\n\"%new[i][4]\n",
    "        f.write(data)\n",
    "    \n",
    "nb_classes = 4\n",
    "nt_order = \"ATGCN\\n\"\n",
    "#PI = array([[0.9938, 0.0005, 0.0049, 0.0008],\n",
    "#          [0.0030, 0.9880, 0.0034, 0.0056],\n",
    "#          [0.0084, 0.0053, 0.9816, 0.0046],\n",
    "#          [0.0006, 0.0042, 0.0008, 0.9944]])\n",
    "H = linalg.inv(PI)\n",
    "LAMBDA = array([[0, 1, 1, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [1, 1, 0, 1],\n",
    "              [1, 1, 1, 0]])\n",
    "S = zeros((nb_classes, nb_classes**nb_classes),dtype=int)\n",
    "for s in range(1,nb_classes**nb_classes):\n",
    "    for x in range(4):\n",
    "        S[x][s] = S[x][s-1]\n",
    "    \n",
    "    if S[0][s] != 3:\n",
    "        S[0][s] += 1\n",
    "        continue\n",
    "    else:\n",
    "        S[0][s] = 0\n",
    "        \n",
    "    if S[1][s] != 3:\n",
    "        S[1][s] += 1\n",
    "        continue\n",
    "    else:\n",
    "        S[1][s] = 0\n",
    "        \n",
    "    if S[2][s] != 3:\n",
    "        S[2][s] += 1\n",
    "        continue\n",
    "    else:\n",
    "        S[2][s] = 0\n",
    "        \n",
    "    if S[3][s] != 3:\n",
    "        S[3][s] += 1\n",
    "        continue\n",
    "    else:\n",
    "        print \"ERROR: S index out of bound!\\n\"\n",
    "RHO   = zeros((nb_classes, nb_classes**nb_classes),dtype=float)\n",
    "RHO_R = zeros((nb_classes, nb_classes*nb_classes),dtype=float)\n",
    "for s in range(nb_classes**nb_classes):\n",
    "    for x in range(4):\n",
    "        RHO[x][s] = (PI[x][0]*LAMBDA[x][S[0][s]] + PI[x][1]*LAMBDA[x][S[1][s]] +\n",
    "                     PI[x][2]*LAMBDA[x][S[2][s]] + PI[x][3]*LAMBDA[x][S[3][s]])\n",
    "for s in range(nb_classes*nb_classes):\n",
    "    for x in range(4):\n",
    "        RHO_R[x][s] = PI[x][int(s/4)]*LAMBDA[x][s%4]\n",
    "L=dot(H,RHO) \n",
    "L_new=-L+amax(L)     # A new loss matrix\n",
    "L_R = dot(H,RHO_R)\n",
    "L_R_new=-L_R+amax(L_R)\n",
    "k_max=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./fold1.fasta\",'r') as tmp:\n",
    "    tmp_ = tmp.readlines()[:50]\n",
    "    for i in range(len(tmp_)):\n",
    "        print tmp_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-17 15:17:39.083984\tIllumina_LinErr_100_fold1_ND5\tPROCESSING START\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6305605e1d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#   For directly generating data for Neural DUDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_data_for_ndude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_R_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/HDD/user/yoon/Yoon_SV4/N-DUDE_SV4/DNA_Sequencing/Data/tetra_dude.pyc\u001b[0m in \u001b[0;36mmake_data_for_ndude\u001b[0;34m(lines, k, L, L_R, nt_order)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mczn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mczn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m#Original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mY_R\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mczn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_R\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m#Reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOG = open(\"log.txt\",\"w\")\n",
    "fold_name = ['fold1']#, 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9']\n",
    "file_stub = 'Illumina_LinErr_'\n",
    "file_name= []\n",
    "for i in range(len(fold_name)):\n",
    "    for j in range(2,10):\n",
    "            continue\n",
    "            name = '%s0%s0_%s' % (file_stub, str(j), fold_name[i])\n",
    "            file_name.append(name)\n",
    "    name = '%s100_%s' % (file_stub, fold_name[i])\n",
    "    file_name.append(name)\n",
    "\n",
    "for k in range(5,6):\n",
    "    for name in file_name:\n",
    "        name_out = name + '_ND' + str(k)\n",
    "        td.PRINT(LOG, \"%s\\tPROCESSING START\" % name_out)\n",
    "        f_in = open(\"%s.fasta\" % name, \"r\")\n",
    "        lines = f_in.readlines()\n",
    "        f_in.close()\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    #   For directly generating data for Neural DUDE\n",
    "    # -----------------------------------------------------\n",
    "        lines,C,Y,Y_R = td.make_data_for_ndude(lines,k,L_new,L_R_new,nt_order)\n",
    "    # -----------------------------------------------------\n",
    "    # -----------------------------------------------------\n",
    "    #   Defining neural networks\n",
    "    # -----------------------------------------------------\n",
    "        model1=Sequential()\n",
    "        model1.add(Dense(2000,input_dim=2*k*(nb_classes),init='he_normal'))\n",
    "        model1.add(Activation('relu'))\n",
    "        model1.add(Dense(2000,init='he_normal'))\n",
    "        model1.add(Activation('relu'))\n",
    "        model1.add(Dense(2000,init='he_normal'))\n",
    "        model1.add(Activation('relu'))\n",
    "        model1.add(Dense(256,init='he_normal'))\n",
    "        model1.add(Activation('softmax'))\n",
    "\n",
    "        rms=RMSprop(lr=0.001, rho=0.9, epsilon=1e-06,clipnorm=1.5)\n",
    "        adagrad=Adagrad(clipnorm=1.5)\n",
    "        adam=Adam()\n",
    "        adadelta=Adadelta()\n",
    "        sgd=SGD(lr=0.01,decay=1e-6,momentum=0.95, nesterov=True, clipnorm=1.0)\n",
    "\n",
    "        model1.compile(loss='poisson', optimizer=adam)\n",
    "\n",
    "        td.PRINT(LOG,'Neural DUDE fitting...')\n",
    "        model1.fit(C,Y,nb_epoch=50,batch_size=500,show_accuracy=False, verbose=1)\n",
    "        td.PRINT(LOG,'Neural DUDE fitting DONE')\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # -----------------------------------------------------\n",
    "    # -----------------------------------------------------\n",
    "        model4=Sequential()\n",
    "        model4.add(Dense(2000,input_dim=2*k*(nb_classes),init='he_normal'))\n",
    "        model4.add(Activation('relu'))\n",
    "        model4.add(Dense(2000,init='he_normal'))\n",
    "        model4.add(Activation('relu'))\n",
    "        model4.add(Dense(2000,init='he_normal'))\n",
    "        model4.add(Activation('relu'))\n",
    "        model4.add(Dense(256,init='he_normal'))\n",
    "        model4.add(Activation('softmax'))\n",
    "\n",
    "        model4.compile(loss='poisson', optimizer=adam)\n",
    "\n",
    "        td.PRINT(LOG,'Neural DUDE2 fitting...')\n",
    "        model4.fit(C,Y,nb_epoch=50,batch_size=500,show_accuracy=False, verbose=1)\n",
    "        td.PRINT(LOG,'Neural DUDE2 fitting DONE')\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "        model2=Graph()\n",
    "        model2.add_input(name='input', input_shape=(2*k*(nb_classes),))\n",
    "        model2.add_node(Dense(400,init='he_normal'), name='layer1', input='input')\n",
    "        model2.add_node(Activation('relu'), name='activation1', input='layer1')\n",
    "        model2.add_node(Dense(400,init='he_normal'), name='layer2', input='activation1')\n",
    "        model2.add_node(Activation('relu'), name='activation2', input='layer2')\n",
    "        model2.add_node(Dense(400,init='he_normal'), name='layer3', input='activation2')\n",
    "        model2.add_node(Activation('relu'), name='activation3', input='layer3')\n",
    "        model2.add_node(Dense(4,init='he_normal'), name='layer4_0', input='activation3')\n",
    "        model2.add_node(Dense(4,init='he_normal'), name='layer4_1', input='activation3')\n",
    "        model2.add_node(Dense(4,init='he_normal'), name='layer4_2', input='activation3')\n",
    "        model2.add_node(Dense(4,init='he_normal'), name='layer4_3', input='activation3')\n",
    "        model2.add_node(Activation('softmax'), name='activation4_0', input='layer4_0')\n",
    "        model2.add_node(Activation('softmax'), name='activation4_1', input='layer4_1')\n",
    "        model2.add_node(Activation('softmax'), name='activation4_2', input='layer4_2')\n",
    "        model2.add_node(Activation('softmax'), name='activation4_3', input='layer4_3')\n",
    "        model2.add_output(name='output0', input='activation4_0')\n",
    "        model2.add_output(name='output1', input='activation4_1')\n",
    "        model2.add_output(name='output2', input='activation4_2')\n",
    "        model2.add_output(name='output3', input='activation4_3')\n",
    "\n",
    "        rms=RMSprop(lr=0.001, rho=0.9, epsilon=1e-06,clipnorm=1.5)\n",
    "        adagrad=Adagrad(clipnorm=1.5)\n",
    "        adam=Adam()\n",
    "        adadelta=Adadelta()\n",
    "        sgd=SGD(lr=0.01,decay=1e-6,momentum=0.95, nesterov=True, clipnorm=1.0)\n",
    "\n",
    "        model2.compile(loss={'output0':'poisson','output1':'poisson','output2':'poisson','output3':'poisson'}, \n",
    "                       optimizer=adam)\n",
    "\n",
    "        #td.PRINT(LOG,'Neural DUDE reduced fitting...')\n",
    "        #model2.fit({'input':C,'output0':Y_R[:,0:4],'output1':Y_R[:,4:8],'output2':Y_R[:,8:12],'output3':Y_R[:,12:16]}, \n",
    "        #           nb_epoch=20,batch_size=500,verbose=1)\n",
    "        #td.PRINT(LOG,'Neural DUDE reduced fitting DONE')\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # -----------------------------------------------------\n",
    "        model3=Graph()\n",
    "        model3.add_input(name='input', input_shape=(2*k*(nb_classes),))\n",
    "        model3.add_node(Dense(400,init='he_normal'), name='layer1', input='input')\n",
    "        model3.add_node(Activation('relu'), name='activation1', input='layer1')\n",
    "        model3.add_node(Dense(400,init='he_normal'), name='layer2', input='activation1')\n",
    "        model3.add_node(Activation('relu'), name='activation2', input='layer2')\n",
    "        model3.add_node(Dense(400,init='he_normal'), name='layer3', input='activation2')\n",
    "        model3.add_node(Activation('relu'), name='activation3', input='layer3')\n",
    "        model3.add_node(Dense(4,init='he_normal'), name='layer4_0', input='activation3')\n",
    "        model3.add_node(Dense(4,init='he_normal'), name='layer4_1', input='activation3')\n",
    "        model3.add_node(Dense(4,init='he_normal'), name='layer4_2', input='activation3')\n",
    "        model3.add_node(Dense(4,init='he_normal'), name='layer4_3', input='activation3')\n",
    "        model3.add_node(Activation('softmax'), name='activation4_0', input='layer4_0')\n",
    "        model3.add_node(Activation('softmax'), name='activation4_1', input='layer4_1')\n",
    "        model3.add_node(Activation('softmax'), name='activation4_2', input='layer4_2')\n",
    "        model3.add_node(Activation('softmax'), name='activation4_3', input='layer4_3')\n",
    "        model3.add_output(name='output0', input='activation4_0')\n",
    "        model3.add_output(name='output1', input='activation4_1')\n",
    "        model3.add_output(name='output2', input='activation4_2')\n",
    "        model3.add_output(name='output3', input='activation4_3')\n",
    "\n",
    "        model3.compile(loss={'output0':'poisson','output1':'poisson','output2':'poisson','output3':'poisson'}, \n",
    "                       optimizer=adam)\n",
    "\n",
    "        #td.PRINT(LOG,'Neural DUDE reduced2 fitting...')\n",
    "        #model3.fit({'input':C,'output0':Y_R[:,0:4],'output1':Y_R[:,4:8],'output2':Y_R[:,8:12],'output3':Y_R[:,12:16]}, \n",
    "        #           nb_epoch=20,batch_size=500,verbose=1)\n",
    "        #td.PRINT(LOG,'Neural DUDE reduced2 fitting DONE')\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "        \n",
    "\n",
    "        td.PRINT(LOG,'Neural DUDE denoising...')\n",
    "        f_out1 = open(\"%s_1.fasta\" % name_out, \"w\")\n",
    "        pred_class1=model1.predict_classes(C, batch_size=200, verbose=0)\n",
    "        td.denoise_with_s(f_out1,lines,pred_class1,k,nt_order)\n",
    "        f_out1.close()\n",
    "        td.PRINT(LOG,'Neural DUDE denoisig DONE')\n",
    "        \n",
    "        td.PRINT(LOG,'Neural DUDE2 denoising...')\n",
    "        f_out4 = open(\"%s_2.fasta\" % name_out, \"w\")\n",
    "        pred_class4=model4.predict_classes(C, batch_size=200, verbose=0)\n",
    "        td.denoise_with_s(f_out4,lines,pred_class4,k,nt_order)\n",
    "        f_out4.close()\n",
    "        td.PRINT(LOG,'Neural DUDE denoisig DONE')\n",
    "        \n",
    "        '''\n",
    "        td.PRINT(LOG,'Neural DUDE reduced denoising...')\n",
    "        f_out2 = open(\"%s_r.fasta\" % name_out, \"w\")\n",
    "        pred2=model2.predict({'input':C}, batch_size=200, verbose=0)\n",
    "        pred_class2 = td.s_R_preprocess(pred2, k)\n",
    "        td.denoise_with_s_R(f_out2,lines,pred_class2,k,nt_order)\n",
    "        f_out2.close()\n",
    "        td.PRINT(LOG,'Neural DUDE reduced denoisig DONE')\n",
    "        \n",
    "        td.PRINT(LOG,'Neural DUDE reduced2 denoising...')\n",
    "        f_out3 = open(\"%s_r2.fasta\" % name_out, \"w\")\n",
    "        pred3=model3.predict({'input':C}, batch_size=200, verbose=0)\n",
    "        pred_class3 = td.s_R_preprocess(pred3, k)\n",
    "        td.denoise_with_s_R(f_out3,lines,pred_class3,k,nt_order)\n",
    "        f_out3.close()\n",
    "        td.PRINT(LOG,'Neural DUDE reduced2 denoisig DONE')\n",
    "\n",
    "        td.PRINT(LOG,'DUDE denoising...')\n",
    "        f_out4 = open(\"%s_DS5_msw.fasta\" % name_out, \"w\")\n",
    "        s_hat= td.dude(lines,k,L) \n",
    "        td.denoise_with_s(f_out4,lines,s_hat,k,nt_order)\n",
    "        f_out4.close()\n",
    "        td.PRINT(LOG,'DUDE denoisig DONE\\n')\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
